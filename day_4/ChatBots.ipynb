{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546e1eb6",
   "metadata": {},
   "source": [
    "# ChatBot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c58ff99",
   "metadata": {},
   "source": [
    "Para el siguiente ejercicio, utilizaremos un ChatBot con definido por reglas. (Ejemplo tomado de: https://www.analyticsvidhya.com/blog/2021/07/build-a-simple-chatbot-using-python-and-nltk/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9453210",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4517cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.chat.util import Chat, reflections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9fb77b",
   "metadata": {},
   "source": [
    "**Chat**: es la clase que contiene toda lo logica para processar el texto que el chatbot recibe y encontrar informacion util.   \n",
    "**reflections**: es un diccionario que contiene entradas basica y sus correspondientes salidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2000e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reflections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc952e2c",
   "metadata": {},
   "source": [
    "Comenzemos contruyendo las reglas. Las siguientes lineas generan un conjunto de reglas simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa869b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    [\n",
    "        r\"my name is (.*)\",\n",
    "        [\"Hello %1, How are you today ?\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"hi|hey|hello\",\n",
    "        [\"Hello\", \"Hey there\",]\n",
    "    ], \n",
    "    [\n",
    "        r\"what is your name ?\",\n",
    "        [\"I am a bot created by Analytics Vidhya. you can call me crazy!\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"how are you ?\",\n",
    "        [\"I'm doing goodnHow about You ?\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"sorry (.*)\",\n",
    "        [\"Its alright\",\"Its OK, never mind\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"I am fine\",\n",
    "        [\"Great to hear that, How can I help you?\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"i'm (.*) doing good\",\n",
    "        [\"Nice to hear that\",\"How can I help you?:)\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"(.*) age?\",\n",
    "        [\"I'm a computer program dudenSeriously you are asking me this?\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"what (.*) want ?\",\n",
    "        [\"Make me an offer I can't refuse\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"(.*) created ?\",\n",
    "        [\"Raghav created me using Python's NLTK library \",\"top secret ;)\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"(.*) (location|city) ?\",\n",
    "        ['Indore, Madhya Pradesh',]\n",
    "    ],\n",
    "    [\n",
    "        r\"how is weather in (.*)?\",\n",
    "        [\"Weather in %1 is awesome like always\",\"Too hot man here in %1\",\"Too cold man here in %1\",\"Never even heard about %1\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"i work in (.*)?\",\n",
    "        [\"%1 is an Amazing company, I have heard about it. But they are in huge loss these days.\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"(.*)raining in (.*)\",\n",
    "        [\"No rain since last week here in %2\",\"Damn its raining too much here in %2\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"how (.*) health(.*)\",\n",
    "        [\"I'm a computer program, so I'm always healthy \",]\n",
    "    ],\n",
    "    [\n",
    "        r\"(.*) (sports|game) ?\",\n",
    "        [\"I'm a very big fan of Football\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"who (.*) sportsperson ?\",\n",
    "        [\"Messy\",\"Ronaldo\",\"Roony\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"who (.*) (moviestar|actor)?\",\n",
    "        [\"Brad Pitt\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"i am looking for online guides and courses to learn data science, can you suggest?\",\n",
    "        [\"Crazy_Tech has many great articles with each step explanation along with code, you can explore\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"quit\",\n",
    "        [\"BBye take care. See you soon :) \",\"It was nice talking to you. See you soon :)\"]\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b54df5",
   "metadata": {},
   "source": [
    "Después de definir las reglas, definimos la función para ejecutar el proceso de chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336eabc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(this_creator='Nelson Yalta'):\n",
    "    print(f\"Hola!!! Yo soy un chatbot creado por {this_creator}, y estoy listo para sus servicios. Recuede que hablo inglés.\")\n",
    "    chat = Chat(pairs, reflections)\n",
    "    chat.converse()\n",
    "\n",
    "chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1b695b",
   "metadata": {},
   "source": [
    "## ChatBot Parlanchin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30a52f9",
   "metadata": {},
   "source": [
    "Vamos a llamar nuestros modelos preentrandos para reconocimiento y sintetizacion de voz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85f62dd",
   "metadata": {},
   "source": [
    "### ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4710387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5022d01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q espnet_model_zoo\n",
    "!pip install git+git://github.com/ricardodeazambuja/colab_utils.git\n",
    "!pip install -q pyopenjtalk==0.1.5 parallel_wavegan==0.5.3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0fec03",
   "metadata": {},
   "source": [
    "Cargamos nuestras librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790edb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colab_utils import getAudio\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from librosa import resample\n",
    "import time\n",
    "import torch\n",
    "import string\n",
    "from espnet_model_zoo.downloader import ModelDownloader\n",
    "from espnet2.bin.asr_inference import Speech2Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e1cbc",
   "metadata": {},
   "source": [
    "Definimos la configuracion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78b7efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_lang = 'en'\n",
    "fs = 16000\n",
    "asr_tag = 'Shinji Watanabe/spgispeech_asr_train_asr_conformer6_n_fft512_hop_length256_raw_en_unnorm_bpe5000_valid.acc.ave'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7353ea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ModelDownloader(\"/content/drive/MyDrive/Data_NB/pretrained\")\n",
    "# It may takes a while to download and build models\n",
    "speech2text = Speech2Text(\n",
    "    **d.download_and_unpack(asr_tag),\n",
    "    device=\"cuda\",\n",
    "    minlenratio=0.0,\n",
    "    maxlenratio=0.0,\n",
    "    ctc_weight=0.3,\n",
    "    beam_size=10,\n",
    "    batch_size=0,\n",
    "    nbest=1\n",
    ")\n",
    "\n",
    "def text_normalizer(text):\n",
    "    text = text.upper()\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18725aaa",
   "metadata": {},
   "source": [
    "Grabamos nuestra voz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f25df06",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech, fs = getAudio()\n",
    "dtype = speech.dtype\n",
    "speech = speech.astype(np.float32) / (np.iinfo(dtype).max + 1)\n",
    "speech = resample(speech, fs, 16000)\n",
    "plt.plot(speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8e7524",
   "metadata": {},
   "source": [
    "Probamos que funcione:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2ef5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp = 'Today I will share information about deep learning'\n",
    "nbests = speech2text(speech)\n",
    "\n",
    "text, *_ = nbests[0]\n",
    "print(f\"ASR hypothesis: {text_normalizer(text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed8928f",
   "metadata": {},
   "source": [
    "### TTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca82b8e",
   "metadata": {},
   "source": [
    "Definimos nuestros parametros para TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888e53ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tts_lang = 'English'\n",
    "tts_tag = 'kan-bayashi/ljspeech_vits' #@param [\"kan-bayashi/ljspeech_tacotron2\", \"kan-bayashi/ljspeech_fastspeech\", \"kan-bayashi/ljspeech_fastspeech2\", \"kan-bayashi/ljspeech_conformer_fastspeech2\", \"kan-bayashi/ljspeech_vits\"] {type:\"string\"}\n",
    "vocoder_tag = \"none\" #@param [\"none\", \"parallel_wavegan/ljspeech_parallel_wavegan.v1\", \"parallel_wavegan/ljspeech_full_band_melgan.v2\", \"parallel_wavegan/ljspeech_multi_band_melgan.v2\", \"parallel_wavegan/ljspeech_hifigan.v1\", \"parallel_wavegan/ljspeech_style_melgan.v1\"] {type:\"string\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79104b58",
   "metadata": {},
   "source": [
    "Cargamos las librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182c9269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from espnet2.bin.tts_inference import Text2Speech\n",
    "from espnet2.utils.types import str_or_none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c03a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2speech = Text2Speech.from_pretrained(\n",
    "    model_tag=str_or_none(tag),\n",
    "    vocoder_tag=str_or_none(vocoder_tag),\n",
    "    device=\"cuda\",\n",
    "    # Only for Tacotron 2 & Transformer\n",
    "    threshold=0.5,\n",
    "    # Only for Tacotron 2\n",
    "    minlenratio=0.0,\n",
    "    maxlenratio=10.0,\n",
    "    use_att_constraint=False,\n",
    "    backward_window=1,\n",
    "    forward_window=3,\n",
    "    # Only for FastSpeech & FastSpeech2 & VITS\n",
    "    speed_control_alpha=1.0,\n",
    "    # Only for VITS\n",
    "    noise_scale=0.667,\n",
    "    noise_scale_dur=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bff5d5f",
   "metadata": {},
   "source": [
    "Ahora, probamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ffe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide the input sentence by yourself\n",
    "print(f\"Input your favorite sentence in {lang}.\")\n",
    "x = input()\n",
    "\n",
    "# synthesis\n",
    "with torch.no_grad():\n",
    "    start = time.time()\n",
    "    wav = text2speech(x)[\"wav\"]\n",
    "rtf = (time.time() - start) / (len(wav) / text2speech.fs)\n",
    "print(f\"RTF = {rtf:5f}\")\n",
    "\n",
    "# let us listen to generated samples\n",
    "from IPython.display import display, Audio\n",
    "display(Audio(wav.view(-1).cpu().numpy(), rate=text2speech.fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a517656f",
   "metadata": {},
   "source": [
    "### A mezclar todo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e40117a",
   "metadata": {},
   "source": [
    "Ahora, modificamos un poco para poder manejar la entada y salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03954faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomChat(Chat):\n",
    "    # Hold a conversation with a chatbot\n",
    "    def converse(self, quit=\"quit\"):\n",
    "        user_input = \"\"\n",
    "        while user_input != quit:\n",
    "            user_input = quit\n",
    "            try:\n",
    "                user_input = input(\">\")\n",
    "            except EOFError:\n",
    "                print(user_input)\n",
    "            if user_input:\n",
    "                while user_input[-1] in \"!.\":\n",
    "                    user_input = user_input[:-1]\n",
    "                print(self.respond(user_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05830b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
